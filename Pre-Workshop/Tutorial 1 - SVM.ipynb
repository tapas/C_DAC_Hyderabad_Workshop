{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of a support vector machine is to find  the optimal separating hyperplane which maximizes the margin of the training data. The first thing we can see from this definition, is that a SVM needs training data, which means it is a supervised learning algorithm. It is also important to know that SVM is a classification algorithm, which means we will use it to predict if something belongs to a particular class.\n",
    "\n",
    "This http://www.svm-tutorial.com/svm-tutorial/ contains a basic tutorial of SVM. It is highly recommended that you read this, before proceeding further with this lab exercise.\n",
    "\n",
    "The first part, you deal with using inbuilt scikit learn SVM function.\n",
    "Note: *StackOverFlow* is programmer's best friend. If you have any doubts syntax related or otherwise, there is a high probability that someone would have already posted about it.\n",
    "\n",
    "We will use Breast cancer database provided by UCI Machine Learning repository. \n",
    "\n",
    "* This https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data contains the breast cancer database. \n",
    "\n",
    "* This https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names contains the details of what each attribute represents in the data. \n",
    "\n",
    "* In short, Class <b> 2 </b> reprsents benign tumour and Class <b> 4 </b> represents malignant tumour.\n",
    "\n",
    "## Using *scikit-learn* svm function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required stuff.\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "#before sklearn 0.18\n",
    "# from sklearn import preprocessing, cross_validation, neighbors, svm\n",
    "\n",
    "from sklearn import preprocessing, neighbors, svm\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the required data. \n",
    "# This data is from UCI Machine Learning repository's Breast cancer database.\n",
    "# https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\n",
    "# Refer to https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names\n",
    "# for more info on data.\n",
    "\n",
    "df = pd.read_csv('data/breast-cancer-wisconsin.data.txt')\n",
    "# Handling missing attributes in data, '?' in data denotes missing attributes\n",
    "df.replace('?', -99999, inplace=True)\n",
    "df.drop(['id'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features and labels.\n",
    "X = np.array(df.drop(['class'], 1))\n",
    "y = np.array(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a random 80-20 split of data for training and testing resp.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using scikit learn's SVM function\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "# Finding the accuracy. Not bad, huh ??\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "# Finding out the prediction of this SVM classifier on new data points. \n",
    "# Here [4,2,1,1,1,2,3,2,1] and [4,2,1,2,2,2,3,2,1] are the two data points\n",
    "example_measures = np.array([[4,2,1,1,1,2,3,2,1], [4,2,1,2,2,2,3,2,1]])\n",
    "\n",
    "# to get of the deprecation error use the line below.\n",
    "example_measures = example_measures.reshape(len(example_measures), -1)\n",
    "\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "  1. What do you think is the significance of this line `df.drop(['id'], 1, inplace=True)` in the above example. Run the above program by commenting out this line. What do you observe and why?\n",
    "  2. Do you observe any difference in accuracy or predictions of SVM and k-NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
